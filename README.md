# Recidivism-Risk-Assessment
In this project, I have applied feature engineering, hyperparameter tuning, andoptimizing for fairness. I have selected metrics, such as accuracy, precision and sensitivity, to use for model optimization as well as one of the mathematical definitions of fairness to evaluate my model. Then, I decided what counts as fair—how similar model performance needs to be forall subgroups in order to conclude that it is fair.

This is a brief introduction of COMPAS (Correctional Offender Management Profiling for Alternative Sanctions), which is a popular commercial algorithm used by judges and parole officers for scoring criminal defendant’s likelihood of reoffending. According to the following article, the algorithm is appar ently biased in favor of white defendants, and against black inmates, according to a 2-year follow-up study those actually committed crime after two years. As a Machine Learning practitioner, it is important to balance the accuracy and the fairness of the ML models so that the resulting AI applications will not negatively affect the lives of other people. 

References:
https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing
